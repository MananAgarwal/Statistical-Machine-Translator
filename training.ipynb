{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# total_k_lines = 100\n",
    "# dutch_data=pd.read_csv(\"Dutch_Updated.txt\",sep='\\n',header=None,skiprows=(2027358-total_k_lines*1000), nrows=total_k_lines*1000)\n",
    "# english_data=pd.read_csv(\"English_Updated.txt\",sep='\\n',header=None,skiprows=(2027358-total_k_lines*1000), nrows=total_k_lines*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING FROM DUTCH TO ENGLISH\n",
    "dutch_data=pd.read_csv(\"Dutch_test_1000.txt\",sep='\\n',header=None)\n",
    "english_data=pd.read_csv(\"English_test_1000.txt\",sep='\\n',header=None)\n",
    "df = pd.DataFrame(columns=['dutch','english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING FROM ENGLISH TO DUTCH\n",
    "# dutch_data=pd.read_csv(\"English_Training.txt\",sep='\\n',header=None)\n",
    "# english_data=pd.read_csv(\"Dutch_Training.txt\",sep='\\n',header=None)\n",
    "# df = pd.DataFrame(columns=['english','dutch'])\n",
    "\n",
    "for a in range(len(english_data)):\n",
    "        df.loc[a] = dutch_data[0][a].split(\" \"),english_data[0][a].split(\" \")\n",
    "\n",
    "del english_data\n",
    "del dutch_data\n",
    "\n",
    "eng_dut_pair = df.to_numpy()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dutch and english vocabularies\n",
    "def vocab(eng_dut_pair):\n",
    "    dutch_words = []\n",
    "    english_words = []\n",
    "\n",
    "    for s_p in eng_dut_pair:\n",
    "        for ew in s_p[1]: \n",
    "            english_words.append(ew)\n",
    "        for fw in s_p[0]: \n",
    "            dutch_words.append(fw)\n",
    "\n",
    "    english_words = sorted(list(set(english_words)), key=lambda s: s.lower()) \n",
    "    dutch_words = sorted(list(set(dutch_words)), key=lambda s: s.lower())\n",
    "    # print('English vocab: ', english_words)\n",
    "    # print('dutch vocab: ',dutch_words)\n",
    "    return english_words,dutch_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size of the english and dutch words\n",
    "def vocab_size(english_words,dutch_words):\n",
    "    english_vocab_size = len(english_words)\n",
    "    dutch_vocab_size = len(dutch_words)\n",
    "    print('english_vocab_size: ', english_vocab_size)\n",
    "    print('dutch_vocab_size: ', dutch_vocab_size)\n",
    "    return english_vocab_size,dutch_vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_vocab_size:  846\n",
      "dutch_vocab_size:  863\n"
     ]
    }
   ],
   "source": [
    "# Routine to uniformly initialize word translation probabilities in t hash\n",
    "def init_prob(t, prev, init_val, eng_dut_pair):\n",
    "    for a in range(len(eng_dut_pair)):\n",
    "        for d_word in eng_dut_pair[a][0]:\n",
    "            for e_word in eng_dut_pair[a][1]:\n",
    "                t[(e_word, d_word)] = init_val\n",
    "                prev[(e_word, d_word)] = 0\n",
    "\n",
    "\n",
    "# Main routine\n",
    "english_words,dutch_words = vocab(eng_dut_pair)\n",
    "english_vocab_size,dutch_vocab_size = vocab_size(english_words,dutch_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of dutch/english pairs:  44559\n",
      "0.18634125144843572\n",
      "0.2488412514484357\n",
      "0.24732187178698567\n",
      "0.1951111342649478\n",
      "0.18615645687166066\n",
      "0.14218162559752567\n",
      "0.10439969734404647\n",
      "0.10482088066128292\n",
      "0.09715745722770464\n",
      "0.08345243095140809\n",
      "0.06832976207467056\n",
      "0.05441326436972238\n",
      "0.048863723302862705\n",
      "0.043278102204199476\n",
      "0.037953677484295345\n",
      "0.03312991472303772\n",
      "0.028884830288305796\n",
      "0.025208334131250343\n",
      "0.02204954806148174\n",
      "0.020421244044887016\n",
      "0.02096573816012437\n",
      "number_of_epochs 21\n",
      "No. of dutch/english pairs: 44559\n",
      "Time taken to train the model 00:00:06\n"
     ]
    }
   ],
   "source": [
    "# Initialize probabilities uniformly\n",
    "final_total = {}\n",
    "t = {}\n",
    "prev = {}\n",
    "init_val = 1.0 / dutch_vocab_size\n",
    "init_prob(t, prev, init_val, eng_dut_pair)\n",
    "\n",
    "print('No. of dutch/english pairs: ', len(t))\n",
    "\n",
    "\n",
    "delta = 1 \n",
    "epsilon = 0.02\n",
    "\n",
    "number_of_epochs = 0\n",
    "# Loop while not converged\n",
    "while (delta > epsilon):\n",
    "\n",
    "    # Initialize\n",
    "    count = {}\n",
    "    total = {}\n",
    "    pair_delta = 0\n",
    "    \n",
    "    for sp in eng_dut_pair:\n",
    "        for fw in sp[0]:\n",
    "            total[fw] = 0.0\n",
    "            for ew in sp[1]:\n",
    "                count[(ew,fw)] = 0.0\n",
    "        \n",
    "    for sp in eng_dut_pair:\n",
    "\n",
    "        # Compute normalization\n",
    "        for ew in sp[1]:\n",
    "            final_total[ew] = 0.0\n",
    "            for fw in sp[0]:\n",
    "                final_total[ew] += t[(ew, fw)]\n",
    "\n",
    "        # Collect counts\n",
    "        for ew in sp[1]:\n",
    "            for fw in sp[0]:\n",
    "                count[(ew, fw)] += t[(ew, fw)] / final_total[ew]\n",
    "                total[fw] += t[(ew, fw)] / final_total[ew]\n",
    "\n",
    "                \n",
    "    for a in range(len(eng_dut_pair)):\n",
    "        for e_word in eng_dut_pair[a][1]:\n",
    "            for d_word in eng_dut_pair[a][0]:\n",
    "                pair_delta = max(pair_delta, abs(prev[(e_word, d_word)]-t[(e_word, d_word)]))\n",
    "                prev[(e_word, d_word)] = t[(e_word, d_word)]\n",
    "                t[(e_word, d_word)] = count[(e_word, d_word)] / total[d_word]\n",
    "                \n",
    "    \n",
    "    number_of_epochs +=1\n",
    "    delta = pair_delta\n",
    "    print(delta)\n",
    "    if(number_of_epochs>20):\n",
    "        break\n",
    "\n",
    "print(\"number_of_epochs\",number_of_epochs)\n",
    "\n",
    "# np.save('Trained_weights.npy', t)\n",
    "\n",
    "#Finding the maximum matrix\n",
    "print(\"No. of dutch/english pairs:\",len(t))\n",
    "\n",
    "convert = {}\n",
    "coverted_prob = {}\n",
    "\n",
    "for p_ed in t.keys():\n",
    "    if p_ed[1] not in coverted_prob.keys():\n",
    "        coverted_prob[p_ed[1]] = 0\n",
    "    if(coverted_prob[p_ed[1]] < t[p_ed]):\n",
    "        coverted_prob[p_ed[1]] = t[p_ed]\n",
    "        convert[p_ed[1]] = p_ed[0]\n",
    "\n",
    "np.save('Trained_mapping.npy',convert)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Time taken to train the model\",time.strftime('%H:%M:%S', time.gmtime(t1-t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
